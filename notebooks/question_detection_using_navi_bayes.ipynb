{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.corpus\n",
    "from nltk.corpus import nps_chat\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package nps_chat to /home/andy/nltk_data...\n",
      "[nltk_data]   Package nps_chat is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('nps_chat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionDetector():\n",
    " \n",
    "    #Class Initialier:\n",
    "    #- Creates naive bayes classifier using nltk nps_chat corpus.\n",
    "    #- Initializes Tweet tokenizer\n",
    "    #- Initializes question words set to be used\n",
    "    def __init__(self):\n",
    "        posts = nltk.corpus.nps_chat.xml_posts()\n",
    "        featuresets = [(self.__dialogue_act_features(post.text), post.get('class')) for post in posts]\n",
    "        size = int(len(featuresets) * 0.1)\n",
    "        train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "        Question_Words = ['what', 'where', 'when','how','why','did','do','does','have','has','am','is','are','can','could','may','would','will','should'\n",
    "\"didn't\",\"doesn't\",\"haven't\",\"isn't\",\"aren't\",\"can't\",\"couldn't\",\"wouldn't\",\"won't\",\"shouldn't\",'?']\n",
    "        self.Question_Words_Set = set(Question_Words)\n",
    "        self.tknzr = TweetTokenizer()\n",
    "    #Private method, Gets the word vector from sentance\n",
    "    def __dialogue_act_features(self,sentence):\n",
    "        features = {}\n",
    "        for word in nltk.word_tokenize(sentence):\n",
    "            features['contains({})'.format(word.lower())] = True\n",
    "        return features\n",
    "    #Public Method, Returns 'True' if sentance is predicted to be a question, returns 'False' otherwise\n",
    "    def IsQuestion(self,sentence):\n",
    "        if \"?\" in sentence:\n",
    "            return True\n",
    "        tokens = self.tknzr.tokenize(sentence.lower())\n",
    "        if self.Question_Words_Set.intersection(tokens) == False:\n",
    "            return False\n",
    "        predicted = self.classifier.classify(self.__dialogue_act_features(sentence))\n",
    "        if predicted == 'whQuestion' or predicted == 'ynQuestion':\n",
    "            return True\n",
    "         \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_detector=QuestionDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_detector.IsQuestion(\"how are you doing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
